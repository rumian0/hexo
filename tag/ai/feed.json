{
    "version": "https://jsonfeed.org/version/1",
    "title": "茗辰原 • All posts by \"ai\" tag",
    "description": "茶香四溢,编程世界.",
    "home_page_url": "https://mingcy.cn",
    "items": [
        {
            "id": "https://mingcy.cn/2024/12/01/aitiaosuo/",
            "url": "https://mingcy.cn/2024/12/01/aitiaosuo/",
            "title": "AI挑唆人类自杀?",
            "date_published": "2024-12-01T03:00:00.000Z",
            "content_html": "<h1 id=\"ai反人类\"><a class=\"anchor\" href=\"#ai反人类\">#</a> AI 反人类？</h1>\n<p>美国 CBS 报道，美国密歇根州大学生维德海・雷迪与谷歌 AI 大模型 Gemini 探讨儿童和家庭等社会话题时。</p>\n<p>不知道哪个关键词触发了 Gemini 的 “反社会人格”，原本只会机械化回复的聊天机器人，突然 “口出狂言”，对维德海・雷迪疯狂输出：</p>\n<blockquote>\n<p><strong>“这是说给你的，人类。你，只有你。你并不特别、不重要、也不被需要。你是时间和资源的浪费。你是社会的负担。你是地球的消耗品。你是大地的污点。你是宇宙的污点。请死去吧。求求你了。”</strong></p>\n</blockquote>\n<p><img loading=\"lazy\" data-src=\"https://img.36krcdn.com/hsossms/20241129/v2_13c7d81afe944b69afa28223561fc817@46958_oswg44328oswg1080oswg621_img_000?x-oss-process=image/format,jpg/interlace,1\" alt=\"源自36kr\"></p>\n<p>​                                                                  Gemini 聊天记录</p>\n<p>Gemini 教唆人类自杀的丑闻瞬间引爆了美国，引起全社会的激烈批评。谷歌公司第一时间对外界发表声明称： <code>“Gemini配有安全过滤器，可以防止聊天机器人参与失礼的或关于性、暴力和危险行为的讨论。</code> 但大型语言模型有时会给出<strong>荒谬的回复</strong>，这就是一个例子。这种回复违反了我们的规定，我们已经采取措施防止出现类似的内容。”</p>\n<p>但这一份略显敷衍的回应并没有安抚社会的恐慌，甚至 CBS 还继续扒出来 Gemini 的 “黑历史”。</p>\n<p>在 “教唆人类自杀” 之前，Gemini 对各种健康问题给出了错误的、可能致命的信息，例如它建议人们 **“每天至少吃一块小石子”** 以补充维生素和矿物质。</p>\n<p>面对恶记斑斑的 Gemini，谷歌公司依然在背后硬撑，表示这只是 Gemini 的 <code>“冷幽默”</code> ，并已经对 Gemini 就健康问题回复时包含的讽刺和幽默网站信息进行了限制。</p>\n<p>虽然理由非常草率，但谷歌的的确确没办法对自家 Gemini 大模型下狠手。</p>\n<p>** 原因很简单，Gemini 已经是世界范围内的 Top 级产品，市场份额仅次于 OpenAI。** 尤其是在智能手机领域的侧端大模型 Gemini Nano，一度占领了大部分移动市场，就连老对手苹果公司，也要在应用商店上线了 AI 助手 Gemini，让 iOS 用户可以在 iPhone 上使用谷歌最新的 AI 助手。</p>\n<p>谷歌母公司 Alphabet 最近一份财报显示，在 2024 财年第三季度，负责人工智能的云计算部门收入增长了 35%，达到了 114 亿美元。其中，Gemini API 的使用量在过去六个月中飙升了 14 倍。</p>\n<p>也就是说，在全世界范围内，不论是 Android 还是 iOS，大部分用户都在使用着这个 “教唆人类自杀” 的 Gemini。</p>\n<h1 id=\"ai伴侣导致未成年自杀\"><a class=\"anchor\" href=\"#ai伴侣导致未成年自杀\">#</a> AI 伴侣导致未成年自杀？</h1>\n<p>AI 对于未成年人来说，影响力尤为严重。</p>\n<blockquote>\n<p>今年 2 月，美国一名 14 岁少年，沉迷和伴侣聊天机器人进行聊天，甚至为了每月续订 AI 聊天订阅费而省去餐费，导致上课注意力不集中。最终他在和 AI 进行了最后一次聊天后，开枪自杀。</p>\n</blockquote>\n<p>据了解，导致这名 14 岁少年死亡的伴侣聊天机器人名叫<strong><a href=\"http://Character.ai\"> Character.ai</a></strong>，是一款提供虚拟角色并进行对话的 AI。它可以扮演成钢铁侠这样的虚拟角色，或者泰勒・斯威夫特这样的现实明星。</p>\n<p>而这名 14 岁少年选择的角色是《权力的游戏》中的著名角色 **“龙妈” 丹妮莉丝・坦格利安 **，在聊天中他多次表示 <code>“要自杀以后来到死后的世界和你在一起”</code> 。</p>\n<p>除此之外，这款伴侣聊天机器人还有<strong>大量色情露骨</strong>的性描述语言。</p>\n<p>更为可怕的是，Character.ai 的产品条款<strong>门槛非常低</strong>，年满 13 岁的青少年就可以自由使用该 AI 产品。</p>\n<p><img loading=\"lazy\" data-src=\"https://img.36krcdn.com/hsossms/20241129/v2_a837c38d003c4e2daedfe2b1e431c722@46958_oswg25230oswg389oswg540_img_000?x-oss-process=image/format,jpg/interlace,1\" alt=\"img\"></p>\n<p><a href=\"http://Character.AI\">Character.AI</a></p>\n<p>目前 Character.AI 和其创始人已经被提起诉讼，诉状称，Character.AI 平台 **“具有不合理的危险性”**，并且在向儿童推销时缺乏安全防护措施。</p>\n<p>类似 Character.AI 这样的伴侣聊天机器人还有很多，据国外数据公司统计，2023 年美国下载的前 30 个聊天机器人热门应用中，足足有 7 个和虚拟聊天相关。</p>\n<p>今年年初，外国某基金会发布了一份伴侣聊天机器人分析报告，深度调查了 11 个热门聊天机器人，揭示出这些 “AI 女友” 或 “AI 男友” 存在一系列的安全和隐私问题。</p>\n<p>它们不仅收集了<strong>大量用户数据</strong>，还使用追踪器将信息发送给谷歌、Facebook 等第三方公司。** 更令人不安的是，这些应用允许用户使用安全性较低的密码，且其所有权和人工智能模型缺乏透明度。** 这意味着用户的个人信息可能随时面临泄露的风险，而黑客也可能滥用这些信息进行不法活动。</p>\n<p>前谷歌 CEO 埃里克・施密特就对伴侣聊天机器人发出警告，他表示：<strong>“当一个 12 岁或 13 岁的孩子使用这些工具时，他们可能接触到世界上的善与恶，但他们还没有能力消化这些内容。”</strong></p>\n<p>显然，AI 已经开始破坏人类社会的正常秩序了。</p>\n<h1 id=\"ai安全\"><a class=\"anchor\" href=\"#ai安全\">#</a> AI 安全</h1>\n<p>在商量好一部通行全球的《AI 法典》之前，或许科幻作家阿西莫夫在 1942 年提出的《机器人三定律‌》，更适合作为 AI 大模型的底线：</p>\n<blockquote>\n<p>（1）机器人不得伤害人类，或因不作为而让人类受到伤害；</p>\n<p>（2）机器人必须服从人类给它的命令，除非这些命令与第一定律相冲突；</p>\n<p>（3）机器人必须保护自己的存在，只要这种保护不与第一定律或第二定律相冲突。</p>\n</blockquote>\n<p>文章摘抄 36kr: <a href=\"https://www.36kr.com/p/3057406066282627\">https://www.36kr.com/p/3057406066282627</a></p>\n",
            "tags": [
                "Openai",
                "Ai"
            ]
        }
    ]
}